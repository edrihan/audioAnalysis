{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edrihan/audioAnalysis/blob/main/tortoise_tts_chess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">Tortoise TTS<font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font color=\"#999\" size=\"4\">Text to spoken word audio</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/NeuralTextToAudio\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a>\n",
        "\n",
        "- All file and directory paths should be relative to your Google Drive root (_My Drive_). E.g. `voice_audio` value should be `Audio/test-voice.wav`, if you have a directory called _Audio_ in your drive, and you want to use _test-voice.wav_ from that directory. Paths are case-sensitive.\n",
        "- This notebook will attempt to prepare a coherent voice dataset from `voice_audio` input, but optimal `voice_audio` for coherent output should be a path to a WAV file of about 1 minute in duration, or a directory containing a total of about 1 minute of WAV files.\n",
        "- In case `voice_audio` contents exceeds 1 minute considerably, random clips (from random file, or files depending on contents, if directory given) will be picked for voice cloning."
      ],
      "metadata": {
        "id": "GBgr33OisX3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisites.<br>\n",
        "#@markdown <small>Mounting Drive will enable this notebook to save outputs directly to your Drive. Otherwise you will need to copy/download them manually from this notebook.</small>\n",
        "\n",
        "force_setup = False\n",
        "repositories = ['https://github.com/neonbjb/tortoise-tts.git']\n",
        "pip_packages = 'scipy transformers==4.19.0'\n",
        "apt_packages = 'sox'\n",
        "mount_drive = False #@param {type:\"boolean\"}\n",
        "skip_setup = False #@ param {type:\"boolean\"}\n",
        "\n",
        "# Download the repo from Github\n",
        "import os\n",
        "from google.colab import output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%cd /content/\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb') and force_setup == False:\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  if apt_packages != '':\n",
        "    !apt-get update && apt-get install {apt_packages}\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if mount_drive == True:\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_root = '/content/drive/My Drive'\n",
        "  if not os.path.isdir('/content/mydrive'):\n",
        "    os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "    drive_root = '/content/mydrive/'\n",
        "  drive_root_set = True\n",
        "else:\n",
        "  create_dirs(['/content/faux_drive'])\n",
        "  drive_root = '/content/faux_drive/'\n",
        "\n",
        "if len(repositories) > 0 and skip_setup == False:\n",
        "  for repo in repositories:\n",
        "    %cd /content/\n",
        "    install_dir = fix_path('/content/'+path_leaf(repo).replace('.git', ''))\n",
        "    repo = repo if '.git' in repo else repo+'.git'\n",
        "    !git clone {repo}\n",
        "    if os.path.isfile(install_dir+'requirements.txt'):\n",
        "      !pip install -r {install_dir}/requirements.txt\n",
        "    if os.path.isfile(install_dir+'setup.py') or os.path.isfile(install_dir+'setup.cfg'):\n",
        "      !pip install -e {install_dir}\n",
        "\n",
        "if len(repositories) == 1:\n",
        "  %cd {install_dir}\n",
        "\n",
        "dir_tmp = '/content/tmp/'\n",
        "dir_tmp_corpus = '/content/tmp/corpus/'\n",
        "dir_tmp_slices = '/content/tmp/slices/'\n",
        "dir_tmp_clips = '/content/tmp/clips/'\n",
        "dir_tmp_processed = '/content/tmp/processed/'\n",
        "create_dirs([dir_tmp, dir_tmp_corpus, dir_tmp_slices, dir_tmp_clips, dir_tmp_processed])\n",
        "\n",
        "import time, sys\n",
        "from datetime import timedelta\n",
        "import math\n",
        "\n",
        "# Imports used through the rest of the notebook.\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import IPython\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_audio, load_voice, load_voices\n",
        "\n",
        "def slice_to_frames(audio_data, slice_duration, fade_in=0, fade_out=0, sr=44100):\n",
        "  a_duration = librosa.get_duration(audio_data, sr=sr)\n",
        "  clips = math.ceil(a_duration/slice_duration)\n",
        "  frames = []\n",
        "  for i in range(clips-1):\n",
        "    if i > 0 and i < clips:\n",
        "      start = i*slice_duration\n",
        "      audio_clip = clip_audio(audio_data, start, slice_duration)\n",
        "      if fade_in > 0 or fade_out > 0:\n",
        "        audio_clip = fade_audio(audio_clip, fade_in, fade_out, sr=sr)\n",
        "      frames.append(audio_clip)\n",
        "  return frames\n",
        "\n",
        "def clip_audio(audio_data, start, duration, sr=44100):\n",
        "  xstart = librosa.time_to_samples(start, sr=sr)\n",
        "  xduration = librosa.time_to_samples(start+duration, sr=sr)\n",
        "  audio_data = audio_data[:, xstart:xduration]\n",
        "  return audio_data\n",
        "\n",
        "def fade_audio(audio_data, fade_in=0.05, fade_out=0.05, sr=44100):\n",
        "  a_duration = librosa.get_duration(audio_data, sr=sr)\n",
        "  if fade_in > 0:\n",
        "    fade_in_to = librosa.time_to_samples(fade_in, sr=sr)\n",
        "    in_y = audio_data[:, 0:fade_in_to]\n",
        "    fade_ins = []\n",
        "    for channel in in_y:\n",
        "      fade = [ i/len(channel)*smp for i, smp in enumerate(channel) ]\n",
        "      fade_ins.append(fade)\n",
        "    fade_ins = np.array(fade_ins)\n",
        "    tail_start = fade_in_to+1\n",
        "    tail = audio_data[:, tail_start:]\n",
        "    audio_data = np.concatenate([fade_ins, tail], axis=1)\n",
        "  if fade_out > 0:\n",
        "    fade_out_start = librosa.time_to_samples(a_duration-fade_out, sr=sr)\n",
        "    out_y = audio_data[:, fade_out_start:]\n",
        "    fade_outs = []\n",
        "    for channel in out_y:\n",
        "      fade = [ smp-(i/len(channel)*smp) for i, smp in enumerate(channel) ]\n",
        "      fade_outs.append(fade)\n",
        "    fade_outs = np.array(fade_outs)\n",
        "    head_start = fade_out_start-1\n",
        "    head = audio_data[:, :head_start]\n",
        "    audio_data = np.concatenate([head, fade_outs], axis=1)\n",
        "  return audio_data\n",
        "\n",
        "def remove_silence(audio, window_size=0.2, threshold=0.1, save_as='', sr=44100):\n",
        "  if type(audio) != np.ndarray:\n",
        "    y, sr = librosa.load(audio, sr=None, mono=False)\n",
        "  else:\n",
        "    y = audio\n",
        "  audio_slices = slice_to_frames(y, window_size, sr=sr)\n",
        "  silence_removed_list = []\n",
        "  for audio_slice in audio_slices:\n",
        "    if max(audio_slice[0]) > threshold or max(audio_slice[1]) < -abs(threshold):\n",
        "      silence_removed_list.append(audio_slice)\n",
        "  silence_removed = np.concatenate(silence_removed_list, axis=1)\n",
        "  if save_as != '':\n",
        "    sf.write(save_as, silence_removed.T, sr)\n",
        "    return save_as\n",
        "  return silence_removed\n",
        "\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "def get_audio_duration(file):\n",
        "  y, sr = librosa.load(voice_file, sr=None, mono=True)\n",
        "  return librosa.get_duration(y, sr=sr)\n",
        "\n",
        "def get_dir_size(dir_path='.'):\n",
        "  total_size = 0\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    for f in filenames:\n",
        "      fp = os.path.join(dirpath, f)\n",
        "      if not os.path.islink(fp):\n",
        "        total_size += os.path.getsize(fp)\n",
        "  return total_size\n",
        "\n",
        "def chop_to_sentences(text):\n",
        "  delimiter = '.'\n",
        "  temp = [e+delimiter for e in text.split(delimiter) if e]\n",
        "  sentences = []\n",
        "  for sentence in temp:\n",
        "    delimiter = '?'\n",
        "    if delimiter in sentence:\n",
        "      wtf = sentence.split(delimiter)\n",
        "      for f in wtf:\n",
        "        if f[-1] != '.' and f[-1] != '?' and f[-1] != '?':\n",
        "          f = f+'?'\n",
        "        if f != '':\n",
        "          sentences.append(f.strip())\n",
        "    elif sentence.strip() != '' and len(sentence.strip()) > 1:\n",
        "      sentences.append(sentence.strip())\n",
        "  return sentences\n",
        "\n",
        "# This will download all the models used by Tortoise from the HuggingFace hub.\n",
        "tts = TextToSpeech()\n",
        "\n",
        "output.clear()\n",
        "# !nvidia-smi\n",
        "op(c.ok, 'Setup finished.', time=True)"
      ],
      "metadata": {
        "id": "Zl44n6FXsbnY",
        "cellView": "form",
        "outputId": "74ecc8c1-ef93-43d9-ff77-dc1c46a310c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2023-08-28 01:27:41 \u001b[92mSetup finished.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade youtube-dl\n",
        "!pip uninstall -y youtube_dl\n",
        "!pip install git+https://github.com/ytdl-org/youtube-dl.git@master#egg=youtube_dl\n",
        "import os\n",
        "!pip install sox\n",
        "#!pip install -U youtube-dl"
      ],
      "metadata": {
        "id": "Go-6bUVpwzXf",
        "outputId": "eb3c4d7c-8f0b-406a-b76d-b52f87a0169c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: youtube-dl 2021.12.17\n",
            "Uninstalling youtube-dl-2021.12.17:\n",
            "  Successfully uninstalled youtube-dl-2021.12.17\n",
            "Collecting youtube_dl\n",
            "  Cloning https://github.com/ytdl-org/youtube-dl.git (to revision master) to /tmp/pip-install-t8diular/youtube-dl_789907be5d4a40a0ba4e452efd278dbc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ytdl-org/youtube-dl.git /tmp/pip-install-t8diular/youtube-dl_789907be5d4a40a0ba4e452efd278dbc\n",
            "  Resolved https://github.com/ytdl-org/youtube-dl.git to commit 86e3cf5e5849aefcc540c19bb5fa5ab7f470d1c1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: youtube_dl\n",
            "  Building wheel for youtube_dl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for youtube_dl: filename=youtube_dl-2021.12.17-py2.py3-none-any.whl size=1939858 sha256=7968193dfee28bd0785757489a3dab9a74f382c756f1f791eadeab581852f6c5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-804nlnne/wheels/b8/03/62/9c414b89a26da510b0a6d984b0ba74200d591e3d0abfa72aa8\n",
            "Successfully built youtube_dl\n",
            "Installing collected packages: youtube_dl\n",
            "Successfully installed youtube_dl-2021.12.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "voices_settings = {\n",
        "    \"sagan\": [\n",
        "        {\n",
        "            'link': 'https://www.youtube.com/watch?v=wupToqz1e2g',\n",
        "            'start_sec': 0,\n",
        "            'end_sec': 17\n",
        "         },\n",
        "        {\n",
        "            'link':'https://www.youtube.com/watch?v=nGanLUnjoPI',\n",
        "            'start_sec': 60,\n",
        "            'end_sec': 60 + 14,\n",
        "        },\n",
        "                {\n",
        "            'link':'https://www.youtube.com/watch?v=UnURElCzGc0',\n",
        "            'start_sec': 3,\n",
        "            'end_sec': 17,\n",
        "        },\n",
        "        {\n",
        "            'link':'https://www.youtube.com/watch?v=UnURElCzGc0',\n",
        "            'start_sec': 3 * 60 + 26,\n",
        "            'end_sec': 3 * 60 + 42,\n",
        "        },\n",
        "       #         {\n",
        "       #     'link':'https://www.loc.gov/item/cosmos000110/',\n",
        "       #     'start_sec': 0,\n",
        "      #     'end_sec': 20,\n",
        "      #  },\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ]\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "for voice, refs in voices_settings.items():\n",
        "  for r, ref in enumerate(refs):\n",
        "\n",
        "    #voice_path = '/content/tortoise-tts/tortoise/voices'\n",
        "    voices_path = os.path.join(drive_root,\"voices\")\n",
        "    voices_path = os.path.join(drive_root)\n",
        "    voice_path = os.path.join(voices_path,voice)\n",
        "    filename =  voice + '.mp4'\n",
        "    filepath = os.path.join(voice_path,filename)\n",
        "    chunkpath =  os.path.join(voice_path,str(r) + '.wav')\n",
        "    command = f'mkdir {voices_path}; cd {voices_path} ; mkdir {voice} ; cd {voice_path};' + \\\n",
        "              f'youtube-dl -x --audio-format wav {ref[\"link\"]} --output \"{str(r)+\"_complete\"}.%(ext)s\"'\n",
        "    print('running command:')\n",
        "    print(command)\n",
        "    !{command}\n",
        "    #Trim\n",
        "\n",
        "    !rm -rf {chunkpath}\n",
        "    command = f\"sox {os.path.join(voice_path,str(r)+'_complete.wav')} {chunkpath} trim {ref['start_sec']} {ref['end_sec'] - ref['start_sec']}\"\n",
        "    print('running command:')\n",
        "    print(command)\n",
        "    !{command}\n",
        "    !rm -rf {os.path.join(voice_path,str(r)+'_complete.wav')}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#!cd /content/faux_drive && youtube-dl --extract-audio --audio-format wav https://lotushelix.bandcamp.com/track/stranger-in-the-street --output \"stranger.wav\"\n",
        "#!cd /content/faux_drive && youtube-dl --extract-audio --audio-format wav https://lotushelix.bandcamp.com/track/live-life-in-love --output \"love.wav\"\n",
        "#!cd /content/faux_drive && youtube-dl --extract-audio --audio-format wav https://youtu.be/3u3JSEqNtlg --output \"technique.wav\"\n",
        "#!cd /content/faux_drive && youtube-dl --extract-audio --audio-format wav https://www.youtube.com/watch?v=wupToqz1e2g --output \"sagan.wav\"\n"
      ],
      "metadata": {
        "id": "McYb8Om5xJF3",
        "outputId": "b00048cc-374a-4529-fc13-2f33adb3ee2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running command:\n",
            "mkdir /content/faux_drive/; cd /content/faux_drive/ ; mkdir sagan ; cd /content/faux_drive/sagan;youtube-dl -x --audio-format wav https://www.youtube.com/watch?v=wupToqz1e2g --output \"0_complete.%(ext)s\"\n",
            "mkdir: cannot create directory ‘/content/faux_drive/’: File exists\n",
            "mkdir: cannot create directory ‘sagan’: File exists\n",
            "[youtube] wupToqz1e2g: Downloading webpage\n",
            "[dashsegments] Total fragments: 1\n",
            "[download] Destination: 0_complete.m4a\n",
            "\u001b[K[download] 100% of 3.26MiB in 00:00\n",
            "[ffmpeg] Correcting container in \"0_complete.m4a\"\n",
            "[ffmpeg] Destination: 0_complete.wav\n",
            "Deleting original file 0_complete.m4a (pass -k to keep)\n",
            "running command:\n",
            "sox /content/faux_drive/sagan/0_complete.wav /content/faux_drive/sagan/0.wav trim 0 17\n",
            "running command:\n",
            "mkdir /content/faux_drive/; cd /content/faux_drive/ ; mkdir sagan ; cd /content/faux_drive/sagan;youtube-dl -x --audio-format wav https://www.youtube.com/watch?v=nGanLUnjoPI --output \"1_complete.%(ext)s\"\n",
            "mkdir: cannot create directory ‘/content/faux_drive/’: File exists\n",
            "mkdir: cannot create directory ‘sagan’: File exists\n",
            "[youtube] nGanLUnjoPI: Downloading webpage\n",
            "[dashsegments] Total fragments: 1\n",
            "[download] Destination: 1_complete.m4a\n",
            "\u001b[K[download] 100% of 3.92MiB in 00:00\n",
            "[ffmpeg] Correcting container in \"1_complete.m4a\"\n",
            "[ffmpeg] Destination: 1_complete.wav\n",
            "Deleting original file 1_complete.m4a (pass -k to keep)\n",
            "running command:\n",
            "sox /content/faux_drive/sagan/1_complete.wav /content/faux_drive/sagan/1.wav trim 60 14\n",
            "running command:\n",
            "mkdir /content/faux_drive/; cd /content/faux_drive/ ; mkdir sagan ; cd /content/faux_drive/sagan;youtube-dl -x --audio-format wav https://www.youtube.com/watch?v=UnURElCzGc0 --output \"2_complete.%(ext)s\"\n",
            "mkdir: cannot create directory ‘/content/faux_drive/’: File exists\n",
            "mkdir: cannot create directory ‘sagan’: File exists\n",
            "[youtube] UnURElCzGc0: Downloading webpage\n",
            "[dashsegments] Total fragments: 1\n",
            "[download] Destination: 2_complete.webm\n",
            "\u001b[K[download] 100% of 7.00MiB in 00:00\n",
            "[ffmpeg] Destination: 2_complete.wav\n",
            "Deleting original file 2_complete.webm (pass -k to keep)\n",
            "running command:\n",
            "sox /content/faux_drive/sagan/2_complete.wav /content/faux_drive/sagan/2.wav trim 3 14\n",
            "running command:\n",
            "mkdir /content/faux_drive/; cd /content/faux_drive/ ; mkdir sagan ; cd /content/faux_drive/sagan;youtube-dl -x --audio-format wav https://www.youtube.com/watch?v=UnURElCzGc0 --output \"3_complete.%(ext)s\"\n",
            "mkdir: cannot create directory ‘/content/faux_drive/’: File exists\n",
            "mkdir: cannot create directory ‘sagan’: File exists\n",
            "[youtube] UnURElCzGc0: Downloading webpage\n",
            "[dashsegments] Total fragments: 1\n",
            "[download] Destination: 3_complete.webm\n",
            "\u001b[K[download] 100% of 7.00MiB in 00:00\n",
            "[ffmpeg] Destination: 3_complete.wav\n",
            "Deleting original file 3_complete.webm (pass -k to keep)\n",
            "running command:\n",
            "sox /content/faux_drive/sagan/3_complete.wav /content/faux_drive/sagan/3.wav trim 206 16\n",
            "running command:\n",
            "mkdir /content/faux_drive/; cd /content/faux_drive/ ; mkdir sagan ; cd /content/faux_drive/sagan;youtube-dl -x --audio-format wav https://www.loc.gov/item/cosmos000110/ --output \"4_complete.%(ext)s\"\n",
            "mkdir: cannot create directory ‘/content/faux_drive/’: File exists\n",
            "mkdir: cannot create directory ‘sagan’: File exists\n",
            "[loc] cosmos000110: Downloading webpage\n",
            "[loc] E6AB0B2585A10180E0438C93F0280180: Downloading JSON metadata\n",
            "[download] Destination: 4_complete.mp3\n",
            "\u001b[K[download] 100% of 3.48MiB in 00:05\n",
            "[ffmpeg] Destination: 4_complete.wav\n",
            "Deleting original file 4_complete.mp3 (pass -k to keep)\n",
            "running command:\n",
            "sox /content/faux_drive/sagan/4_complete.wav /content/faux_drive/sagan/4.wav trim 0 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Generate spoken word audio\n",
        "text = \"pawn to ay 1. pawn to ay 2. pawn to ay 3. pawn to ay 4. pawn to ay 5. pawn to ay 6. pawn to ay 7. pawn to ay 8. pawn to bee 1. pawn to bee 2. pawn to bee 3. pawn to bee 4. pawn to bee 5. pawn to bee 6. pawn to bee 7. pawn to bee 8. pawn to sea 1. pawn to sea 2. pawn to sea 3. pawn to sea 4. pawn to sea 5. pawn to sea 6. pawn to sea 7. pawn to sea 8. pawn to dee 1. pawn to dee 2. pawn to dee 3. pawn to dee 4. pawn to dee 5. pawn to dee 6. pawn to dee 7. pawn to dee 8. pawn to ee 1. pawn to ee 2. pawn to ee 3. pawn to ee 4. pawn to ee 5. pawn to ee 6. pawn to ee 7. pawn to ee 8. pawn to eff 1. pawn to eff 2. pawn to eff 3. pawn to eff 4. pawn to eff 5. pawn to eff 6. pawn to eff 7. pawn to eff 8. pawn to jee 1. pawn to jee 2. pawn to jee 3. pawn to jee 4. pawn to jee 5. pawn to jee 6. pawn to jee 7. pawn to jee 8. pawn to aych 1. pawn to aych 2. pawn to aych 3. pawn to aych 4. pawn to aych 5. pawn to aych 6. pawn to aych 7. pawn to aych 8. rook to ay 1. rook to ay 2. rook to ay 3. rook to ay 4. rook to ay 5. rook to ay 6. rook to ay 7. rook to ay 8. rook to bee 1. rook to bee 2. rook to bee 3. rook to bee 4. rook to bee 5. rook to bee 6. rook to bee 7. rook to bee 8. rook to sea 1. rook to sea 2. rook to sea 3. rook to sea 4. rook to sea 5. rook to sea 6. rook to sea 7. rook to sea 8. rook to dee 1. rook to dee 2. rook to dee 3. rook to dee 4. rook to dee 5. rook to dee 6. rook to dee 7. rook to dee 8. rook to ee 1. rook to ee 2. rook to ee 3. rook to ee 4. rook to ee 5. rook to ee 6. rook to ee 7. rook to ee 8. rook to eff 1. rook to eff 2. rook to eff 3. rook to eff 4. rook to eff 5. rook to eff 6. rook to eff 7. rook to eff 8. rook to jee 1. rook to jee 2. rook to jee 3. rook to jee 4. rook to jee 5. rook to jee 6. rook to jee 7. rook to jee 8. rook to aych 1. rook to aych 2. rook to aych 3. rook to aych 4. rook to aych 5. rook to aych 6. rook to aych 7. rook to aych 8. knight to ay 1. knight to ay 2. knight to ay 3. knight to ay 4. knight to ay 5. knight to ay 6. knight to ay 7. knight to ay 8. knight to bee 1. knight to bee 2. knight to bee 3. knight to bee 4. knight to bee 5. knight to bee 6. knight to bee 7. knight to bee 8. knight to sea 1. knight to sea 2. knight to sea 3. knight to sea 4. knight to sea 5. knight to sea 6. knight to sea 7. knight to sea 8. knight to dee 1. knight to dee 2. knight to dee 3. knight to dee 4. knight to dee 5. knight to dee 6. knight to dee 7. knight to dee 8. knight to ee 1. knight to ee 2. knight to ee 3. knight to ee 4. knight to ee 5. knight to ee 6. knight to ee 7. knight to ee 8. knight to eff 1. knight to eff 2. knight to eff 3. knight to eff 4. knight to eff 5. knight to eff 6. knight to eff 7. knight to eff 8. knight to jee 1. knight to jee 2. knight to jee 3. knight to jee 4. knight to jee 5. knight to jee 6. knight to jee 7. knight to jee 8. knight to aych 1. knight to aych 2. knight to aych 3. knight to aych 4. knight to aych 5. knight to aych 6. knight to aych 7. knight to aych 8. bishop to ay 1. bishop to ay 2. bishop to ay 3. bishop to ay 4. bishop to ay 5. bishop to ay 6. bishop to ay 7. bishop to ay 8. bishop to bee 1. bishop to bee 2. bishop to bee 3. bishop to bee 4. bishop to bee 5. bishop to bee 6. bishop to bee 7. bishop to bee 8. bishop to sea 1. bishop to sea 2. bishop to sea 3. bishop to sea 4. bishop to sea 5. bishop to sea 6. bishop to sea 7. bishop to sea 8. bishop to dee 1. bishop to dee 2. bishop to dee 3. bishop to dee 4. bishop to dee 5. bishop to dee 6. bishop to dee 7. bishop to dee 8. bishop to ee 1. bishop to ee 2. bishop to ee 3. bishop to ee 4. bishop to ee 5. bishop to ee 6. bishop to ee 7. bishop to ee 8. bishop to eff 1. bishop to eff 2. bishop to eff 3. bishop to eff 4. bishop to eff 5. bishop to eff 6. bishop to eff 7. bishop to eff 8. bishop to jee 1. bishop to jee 2. bishop to jee 3. bishop to jee 4. bishop to jee 5. bishop to jee 6. bishop to jee 7. bishop to jee 8. bishop to aych 1. bishop to aych 2. bishop to aych 3. bishop to aych 4. bishop to aych 5. bishop to aych 6. bishop to aych 7. bishop to aych 8. king to ay 1. king to ay 2. king to ay 3. king to ay 4. king to ay 5. king to ay 6. king to ay 7. king to ay 8. king to bee 1. king to bee 2. king to bee 3. king to bee 4. king to bee 5. king to bee 6. king to bee 7. king to bee 8. king to sea 1. king to sea 2. king to sea 3. king to sea 4. king to sea 5. king to sea 6. king to sea 7. king to sea 8. king to dee 1. king to dee 2. king to dee 3. king to dee 4. king to dee 5. king to dee 6. king to dee 7. king to dee 8. king to ee 1. king to ee 2. king to ee 3. king to ee 4. king to ee 5. king to ee 6. king to ee 7. king to ee 8. king to eff 1. king to eff 2. king to eff 3. king to eff 4. king to eff 5. king to eff 6. king to eff 7. king to eff 8. king to jee 1. king to jee 2. king to jee 3. king to jee 4. king to jee 5. king to jee 6. king to jee 7. king to jee 8. king to aych 1. king to aych 2. king to aych 3. king to aych 4. king to aych 5. king to aych 6. king to aych 7. king to aych 8. queen to ay 1. queen to ay 2. queen to ay 3. queen to ay 4. queen to ay 5. queen to ay 6. queen to ay 7. queen to ay 8. queen to bee 1. queen to bee 2. queen to bee 3. queen to bee 4. queen to bee 5. queen to bee 6. queen to bee 7. queen to bee 8. queen to sea 1. queen to sea 2. queen to sea 3. queen to sea 4. queen to sea 5. queen to sea 6. queen to sea 7. queen to sea 8. queen to dee 1. queen to dee 2. queen to dee 3. queen to dee 4. queen to dee 5. queen to dee 6. queen to dee 7. queen to dee 8. queen to ee 1. queen to ee 2. queen to ee 3. queen to ee 4. queen to ee 5. queen to ee 6. queen to ee 7. queen to ee 8. queen to eff 1. queen to eff 2. queen to eff 3. queen to eff 4. queen to eff 5. queen to eff 6. queen to eff 7. queen to eff 8. queen to jee 1. queen to jee 2. queen to jee 3. queen to jee 4. queen to jee 5. queen to jee 6. queen to jee 7. queen to jee 8. queen to aych 1. queen to aych 2. queen to aych 3. queen to aych 4. queen to aych 5. queen to aych 6. queen to aych 7. queen to aych 8\" #@param {type:\"string\"}\n",
        "voice_audio = \"sagan\" #@param {type:\"string\"}\n",
        "combo_voice = False #@ param {type:\"boolean\"}\n",
        "preset = \"high_quality\" #@param [\"standard\", \"fast\", \"ultra_fast\", \"high_quality\"]\n",
        "output_dir = \"fullset\" #@param {type:\"string\"}\n",
        "end_session_when_done = False #@ param {type: \"boolean\"}\n",
        "\n",
        "save_txt = True\n",
        "timer_start = time.time()\n",
        "uniq_id = gen_id()\n",
        "\n",
        "\n",
        "slice_length = 12 # seconds per slice\n",
        "use_slices = 5 # slices to use\n",
        "optimal_samples_duration = slice_length * use_slices # total duration\n",
        "sample_rate = 24000\n",
        "#process this many sentences in one go\n",
        "# @markdown try lowering this if you run out of VRAM:\n",
        "chunk_sentences = 10 #@param {type:\"integer\", description:\"If you run out of (v)RAM try lowering this\"}\n",
        "dir_byte_limit = 48000000\n",
        "merge_sentences = True\n",
        "\n",
        "op(c.title, 'Run ID:', uniq_id, time=True)\n",
        "print()\n",
        "\n",
        "voice_corpus = voice_audio\n",
        "prompts = chop_to_sentences(text)\n",
        "\n",
        "if chunk_sentences > 1:\n",
        "  prompts = [''.join(prompts[i:i+chunk_sentences]) for i in range(0, len(prompts), chunk_sentences)]\n",
        "\n",
        "clean_dirs([dir_tmp_corpus, dir_tmp_slices, dir_tmp_clips, dir_tmp_processed])\n",
        "\n",
        "if os.path.isfile(drive_root+voice_corpus):\n",
        "  clean_dirs([dir_tmp_corpus])\n",
        "  shutil.copy(drive_root+voice_corpus, dir_tmp_corpus)\n",
        "  voice_dirs = [dir_tmp_corpus]\n",
        "else:\n",
        "  if voice_corpus == 'voice_list':\n",
        "    voice_dirs = [drive_root+x for x in voice_list]\n",
        "  elif ',' in voice_corpus:\n",
        "    voice_dirs = [drive_root+fix_path(x.strip()) for x in voice_corpus.split(',')]\n",
        "  elif ';' in voice_corpus:\n",
        "    voice_dirs = [drive_root+fix_path(x.strip()) for x in voice_corpus.split(';')]\n",
        "  else:\n",
        "    voice_dirs = [drive_root+fix_path(voice_corpus)]\n",
        "\n",
        "# Output\n",
        "if output_dir == '':\n",
        "  if mount_drive == True:\n",
        "    dir_out = dir_tmp\n",
        "  else:\n",
        "    dir_out = drive_root\n",
        "else:\n",
        "  if not os.path.isdir(drive_root+output_dir):\n",
        "    os.mkdir(drive_root+output_dir)\n",
        "  dir_out = drive_root+fix_path(output_dir)\n",
        "\n",
        "total = len(voice_dirs * len(prompts))\n",
        "use_voices = []\n",
        "\n",
        "txt_file = dir_out+uniq_id+'.txt'\n",
        "if save_txt: append_txt(txt_file, timestamp(human_readable=True)+' '+uniq_id+'\\n\\n'+text+'\\n\\n'+'combo_voice: '+str(combo_voice)+'\\n'+'preset: '+preset+'\\n'+'dir_out: '+dir_out+'\\n\\n')\n",
        "\n",
        "for i, voice_dir in enumerate(voice_dirs, 1):\n",
        "  if voice_dir == dir_tmp_corpus:\n",
        "    voice_name = basename(voice_corpus)\n",
        "  else:\n",
        "    voice_name = path_leaf(voice_dir)\n",
        "\n",
        "  use_voices.append(voice_name)\n",
        "  new_voice_dir = '/content/tortoise-tts/tortoise/voices/'+voice_name+'/'\n",
        "  if not os.path.isdir(new_voice_dir):\n",
        "    os.mkdir(new_voice_dir)\n",
        "  else:\n",
        "    clean_dirs([new_voice_dir])\n",
        "  voice_files = list_audio(voice_dir)\n",
        "\n",
        "  random.shuffle(voice_files)\n",
        "\n",
        "  if save_txt: append_txt(txt_file, voice_name+'\\n'+'In: '+voice_dir)\n",
        "\n",
        "  if len(voice_files) == 0:\n",
        "    print()\n",
        "    op(c.fail, 'Skipping '+voice_name+' - Reason: WAV files not found in dir:', voice_dir.replace(drive_root, ''), time=True)\n",
        "    if save_txt: append_txt(txt_file, 'Out: - (no wav found, SKIP)\\n')\n",
        "  else:\n",
        "    op(c.okb, 'Processing voice files...', time=True)\n",
        "    bytes_collected = 0\n",
        "    for voice_file in voice_files:\n",
        "      voice_file = remove_silence(voice_file, window_size=2, threshold=0.1, save_as=dir_tmp_processed+path_leaf(voice_file))\n",
        "      file_duration = get_audio_duration(voice_file)\n",
        "      slice_file = dir_tmp_slices+path_leaf(voice_file)\n",
        "\n",
        "      if file_duration > slice_length:\n",
        "        !sox {sox_q} \"{voice_file}\" -r 22050 {slice_file} trim 0 {slice_length} : newfile : restart\n",
        "      else:\n",
        "        !sox {sox_q} \"{voice_file}\" -r 22050 {slice_file}\n",
        "\n",
        "      clips = list_audio(dir_tmp_slices)\n",
        "\n",
        "      short_clips = []\n",
        "      long_clips = []\n",
        "      for clip in clips:\n",
        "        clip_duration = get_audio_duration(clip)\n",
        "        if clip_duration >= slice_length:\n",
        "          long_clips.append(clip)\n",
        "        else:\n",
        "          short_clips.append(clip)\n",
        "        if (len(long_clips)*slice_length >= optimal_samples_duration):\n",
        "          break\n",
        "\n",
        "      if len(long_clips) >= use_slices:\n",
        "        selected_clips = random.sample(long_clips, use_slices)\n",
        "      else:\n",
        "        selected_clips = clips\n",
        "\n",
        "      if save_txt: append_txt(txt_file, 'Selected clips:')\n",
        "      for clip in selected_clips:\n",
        "        if save_txt: append_txt(txt_file, path_leaf(clip)+'\\n')\n",
        "        shutil.copy(clip, new_voice_dir)\n",
        "\n",
        "      file_size = os.path.getsize(voice_file)\n",
        "      bytes_collected += file_size\n",
        "      if bytes_collected > dir_byte_limit:\n",
        "        break\n",
        "\n",
        "    merge_list = []\n",
        "    for ii, text in enumerate(prompts, 1):\n",
        "\n",
        "      ndx_info = str(i*ii)+'/'+str(total)+' '\n",
        "\n",
        "      voice_samples = None\n",
        "      conditioning_latents = None\n",
        "      gen = None\n",
        "\n",
        "      print()\n",
        "      op(c.title, ndx_info+'Processing', voice_name, time=True)\n",
        "\n",
        "      if combo_voice == False:\n",
        "        op(c.title, ndx_info+'Synthesizing', text+'...', time=True)\n",
        "\n",
        "        file_out = dir_out+uniq_id+'__'+voice_name+'_'+str(ii).zfill(3)+'_'+slug(text[:60])+'.wav'\n",
        "        if save_txt: append_txt(txt_file, 'Out: '+file_out+'\\n')\n",
        "        voice_samples, conditioning_latents = load_voice(voice_name)\n",
        "        gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents, preset=preset)\n",
        "        torchaudio.save(file_out, gen.squeeze(0).cpu(), sample_rate)\n",
        "        if os.path.isfile(file_out):\n",
        "          op(c.ok, 'Saved', file_out.replace(drive_root, ''), time=True)\n",
        "          merge_list.append(file_out)\n",
        "        else:\n",
        "          op(c.fail, 'Error saving', file_out.replace(drive_root, ''), time=True)\n",
        "\n",
        "        del voice_samples\n",
        "        del conditioning_latents\n",
        "        del gen\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "      import gc\n",
        "      gc.collect()\n",
        "\n",
        "    if merge_sentences == True:\n",
        "      sox_input_list = ' '.join(merge_list)\n",
        "      sox_merge_out = dir_out+uniq_id+'__'+voice_name+'_FULL.wav'\n",
        "      !sox {sox_q} {sox_input_list} {sox_merge_out}\n",
        "\n",
        "# if combo_voice == True:\n",
        "#   for text in prompts:\n",
        "#     print()\n",
        "#     op(c.title, 'Synthesizing', text[:40]+'...', time=True)\n",
        "#     file_out = dir_out+uniq_id+'__'+voice_name+'_'+slug(text[:60])+'.wav'\n",
        "#     if save_txt == True:\n",
        "#       append_txt(txt_file, 'Out: '+file_out+'\\n')\n",
        "#     voice_samples, conditioning_latents = load_voices(use_voices)\n",
        "#     gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents, preset=preset)\n",
        "#     torchaudio.save(file_out, gen.squeeze(0).cpu(), sample_rate)\n",
        "#     # IPython.display.Audio(file_out)\n",
        "\n",
        "#     del voice_samples\n",
        "#     del conditioning_latents\n",
        "#     del gen\n",
        "#     # del tts\n",
        "#     torch.cuda.empty_cache()\n",
        "#     import gc\n",
        "#     gc.collect()\n",
        "\n",
        "\n",
        "timer_end = time.time()\n",
        "\n",
        "print()\n",
        "\n",
        "if save_txt: append_txt(txt_file, str(timedelta(seconds=timer_end-timer_start)) )\n",
        "if save_txt: append_txt(txt_file, 'Finished at '+timestamp(human_readable=True))\n",
        "\n",
        "op(c.okb, 'Elapsed', timedelta(seconds=timer_end-timer_start), time=True)\n",
        "op(c.ok, 'FIN.')\n",
        "\n",
        "if end_session_when_done is True: end_session()"
      ],
      "metadata": {
        "id": "DjMTvst0z2ng",
        "outputId": "b3d9c604-bc31-4d3c-c811-613fa6e1b224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2023-08-28 04:04:31 \u001b[96mRun ID:\u001b[0m galfaf\n",
            "\n",
            "\u001b[90m2023-08-28 04:04:31 \u001b[94mProcessing voice files...\u001b[0m\n",
            "sox WARN trim: Last 1 position(s) not reached (audio shorter than expected).\n",
            "sox WARN trim: Last 1 position(s) not reached (audio shorter than expected).\n",
            "\n",
            "\u001b[90m2023-08-28 04:04:32 \u001b[96m1/39 Processing\u001b[0m sagan\n",
            "\u001b[90m2023-08-28 04:04:32 \u001b[96m1/39 Synthesizing\u001b[0m pawn to ay 1.pawn to ay 2.pawn to ay 3.pawn to ay 4.pawn to ay 5.pawn to ay 6.pawn to ay 7.pawn to ay 8.pawn to bee 1.pawn to bee 2....\n",
            "Generating autoregressive samples..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▋         | 1/16 [10:45<2:41:22, 645.52s/it]"
          ]
        }
      ]
    }
  ]
}